ğŸ¨ Text2Image Diffusion Engine
A Text-to-Image generation system powered by Stable Diffusion that converts natural language prompts into high-quality images.
The project provides both a Command Line Interface (CLI) and an interactive Streamlit Web UI with automatic hardware optimization and fast generation support.

ğŸš€ Features

- ğŸ§  Text-to-Image generation using Stable Diffusion
- âš¡ Fast Mode (LCM) for faster CPU inference
- ğŸ’» Command Line Interface (CLI)
- ğŸŒ Streamlit Web Interface
- ğŸ›ï¸ Fully customizable generation parameters
- ğŸ” Automatic device detection (CUDA / MPS / CPU)
- ğŸ¯ Seed support for reproducible results
- ğŸš« Negative prompt support
- ğŸ’¾ Automatic image saving

ğŸ“ Project Structure

â”œâ”€â”€ main.py                # CLI entry point
â”œâ”€â”€ streamlit_app.py       # Streamlit Web UI
â”œâ”€â”€ model_loader.py        # Model loading & device optimization
â”œâ”€â”€ image_generator.py     # Image generation logic
â”œâ”€â”€ download_model.py      # Model downloader
â”œâ”€â”€ test_installation.py   # Environment verification
â”œâ”€â”€ test_lcm.py            # Fast mode testing
â”œâ”€â”€ requirements.txt       # Dependencies
â””â”€â”€ outputs/               # Generated images

âš™ï¸ Installation

ğŸ“¥ Clone Repository

```
git clone https://github.com/your-username/text2image-diffusion-engine.git
cd text2image-diffusion-engine
```
ğŸ“¦ Install Dependencies

```
pip install -r requirements.txt
```

---

âœ… Verify Installation (Optional)

```
python test_installation.py
```

---

ğŸ–¥ï¸ Usage

â–¶ï¸ Command Line Interface (CLI)

Basic usage:

```
python main.py "A futuristic city in the clouds"
```

Advanced usage:

```
python main.py "Cyberpunk city at night" --negative_prompt "blurry, low quality" --steps 30 --guidance_scale 8.0 --width 512 --height 512 --num_images 2
```

---

ğŸŒ Streamlit Web Interface

Run the web application:

```
streamlit run streamlit_app.py
```

Then open the browser and generate images interactively.

---

âš¡ Fast Mode (LCM)

Fast Mode significantly reduces generation time, especially on CPU devices.

Enable Fast Mode:

```
python main.py "A fantasy landscape" --fast
```

Typical settings:
- âš¡ Steps: 4 to 8
- ğŸ¯ Guidance Scale: 1.0

---
ğŸ›ï¸ Parameters

- ğŸ“ Prompt â€” Text description of the image
- ğŸš« Negative Prompt â€” Elements to avoid
- â±ï¸ Inference Steps â€” Controls quality vs speed
- ğŸ¯ Guidance Scale â€” Prompt adherence strength
- ğŸ–¼ï¸ Image Size â€” Width and height
- ğŸ” Seed â€” Reproducible outputs
- ğŸ§© Number of Images â€” Batch generation

---

ğŸ§  How It Works

1. Text prompt is converted into embeddings using a text encoder.
2. Stable Diffusion starts from random noise.
3. The diffusion process iteratively denoises guided by the prompt.
4. The final latent representation is decoded into an image.

---

ğŸ’» Requirements

- Python 3.8 or higher
- Recommended GPU with at least 4GB VRAM
- CPU generation supported (slower but optimized)

---

ğŸ“¦ Dependencies

- torch
- diffusers
- transformers
- accelerate
- streamlit
- Pillow
- peft

Install automatically:

```
pip install -r requirements.txt
```

---

ğŸ“¸ Output

Generated images are automatically saved inside:

```
outputs/
```

---

ğŸ› ï¸ Troubleshooting

Out of Memory:
- Reduce image size (256x256)
- Generate fewer images
- Use Fast Mode

Slow Generation:
- CPU inference is slower
- Use GPU if available

